# -*- coding: utf-8 -*-
"""Bank data | Classification| ML

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jVi7-7TXl9a8WTjSnPc_xNU2SMKJPHhw

## **Import Libraries:**
"""

# support display of warning
import warnings
warnings.filterwarnings('ignore')

# 'pandas' is used for data manipulation and analysis
import pandas as pd

# 'numpy' is used for mathmetically operation on large , multi-dimensional array and matrices
import numpy as numpy

# matplotlib is a data visualization library for 20 & 30 plots, built on numpy
import matplotlib.pyplot as plt

# 'seaborn' is a data visualization library built on matplotlib
import seaborn as sns

# import various function to perform classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# classification model
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

import pandas as pd
bank = pd.read_csv('/content/bank data.zip')
bank

"""## **EDA:**

Goal:- The classification goal is to predict if the client will subscribe (yes/no) a term deposit (target 'y').
"""

bank.head()

bank.tail()

bank.info()

"""### **Missing Value Check:**"""

bank.isnull().sum()

bank.duplicated().sum()

bank.drop_duplicates(inplace=True)

bank.duplicated().sum()

bank.columns

col = [  'job', 'marital', 'education', 'default', 'housing', 'loan',
       'contact', 'month', 'day_of_week', 'poutcome', 'y']
for i in col:
  print(bank[i].value_counts())

# Optional: group similar education levels
bank['education'] = bank['education'].replace({
    'basic_9y': 'basic',
    'basic_4y': 'basic',
    'basic_6y': 'basic'
})

bank.head()

"""## 1- **Composition:**"""

bank.shape
print("Number of rows:", bank.shape[0])
print("Number of columns:", bank.shape[1])

# composition of features
bank.describe()

#plot for composition of features
sns.pairplot(bank)
plt.show()

"""## 2- **Combination:**"""

sns.boxplot(x='y', y='duration', data=bank)
plt.title('Duration vs Response')

plt.figure(figsize=(12,6))
sns.countplot(data=bank, x='job', hue='education')
plt.xticks(rotation=45)
plt.title('Job vs Education Levels')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,5))
sns.countplot(data=bank, x='marital', hue='housing')
plt.title('Marital Status vs Housing Loan')
plt.show()

plt.figure(figsize=(10,5))
sns.countplot(data=bank, x='marital', hue='loan')
plt.title('Marital Status vs Personal Loan')
plt.show()

sns.countplot(data=bank, x='poutcome', hue='y')
plt.title('Previous Campaign Outcome vs Current Response')
plt.xticks(rotation=45)
plt.show()

"""## 3- **Distribution:**"""

num_cols = ['age', 'duration', 'campaign', 'previous']

for col in num_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(bank[col], kde=True, bins=30, color='teal')
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.tight_layout()
    plt.show()

cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome', 'y']

for col in cat_cols:
    plt.figure(figsize=(10, 4))
    sns.countplot(data=bank, x=col, order=bank[col].value_counts().index, palette='Set2')
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

for col in num_cols:
    plt.figure(figsize=(8, 4))
    sns.histplot(data=bank, x=col, hue='y', kde=True, bins=30)
    plt.title(f'{col} Distribution by Campaign Response')
    plt.tight_layout()
    plt.show()

# plot as target y for distribution
plt.figure(figsize=(10, 4))
sns.countplot(data=bank, x='y', order=bank['y'].value_counts().index, palette='Set2')
plt.title('Distribution of Campaign Response')

"""## 4- **Correlation:**"""

correlation_matrix = bank.select_dtypes(include=['int64', 'float64']).corr()
plt.figure(figsize=(12, 8))

# Heatmap
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5)
plt.title('Correlation Matrix of Numerical Features')
plt.tight_layout()
plt.show()

"""### Inconsistency check"""

bank['y'].value_counts()

# Normal distribution
bank.hist(figsize=(12, 12))
plt.show()

# normalize target column
bank['y'].value_counts(normalize=True)

# plot as target y for distribution
plt.figure(figsize=(10, 4))
sns.countplot(data=bank, x='y', order=bank['y'].value_counts().index, palette='Set2')
plt.title('Distribution of Campaign Response')

bank.head()

numcols = bank.select_dtypes(include="int64")
numcols.columns

sns.pairplot(bank)

"""## **Data Preprocessing:**"""

# Extracting categorical columns:
catFeatures= [col for col in bank.columns if col in
              bank.select_dtypes(include=object).columns]

# # Extracting All Features:
features = [col for col in bank.columns if col not in ['y']]

print(features)
catFeatures

# Extracting categorical columns:
catFeatures= [col for col in bank.columns if col in
              bank.select_dtypes(include=object).columns]

from sklearn.preprocessing import LabelEncoder
X = bank
# Encoding Categorical Data
labelEncode = LabelEncoder()

# Iterating Over each categorial features:
for col in catFeatures:
    # storing its numerical value:
    X[col] = labelEncode.fit_transform(bank[col])

"""# **Correlation:**"""

# correlation
corr = X.corr()
corr

# correlation heat map
plt.figure(figsize=(12,10))
sns.heatmap(corr, annot=True)
plt.title('Correlation Heatmap')
plt.show()

Y = bank[['y']]
X = bank.drop(['y'], axis=1)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.80, random_state=42)

X.head()

X_train.shape

models = {
    "                   Logistic Regression": LogisticRegression(),
    "                  Gaussian Naive Bayes": GaussianNB(),
    "                   K-Nearest Neighbors": KNeighborsClassifier(),
    "             Support Vector Classifier": SVC(),
    "                          RandomForest": RandomForestClassifier()
}

for name, model in models.items():
    model.fit(X_train, Y_train)
    print(name + " trained.")

for name, model in models.items():
    print(name + ": {:.2f}%".format(model.score(X_test, Y_test) * 100))
    # .score (y_pred & x_ pred) k bjay use hoga
    # .2f % is used for 2 decimal point

print("Before Smote")
print('''Logistic Regression: 89.85%
        Gaussian Naive Bayes: 87.57%
        K-Nearest Neighbors: 89.63%
        Support Vector Machine: 89.86%
        RandomForest: 90.06%''')

Y.value_counts()

for name, model in models.items():
  y_pred = model.predict(X_test)
  # PRINT THE CONFUSION MATRIX
  print("Confusion Matrix")
  cm = confusion_matrix(Y_test, y_pred)
  print(cm)
  plt.figure(figsize = (6, 4))
  sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', cbar = False, annot_kws = {'size' : 14})
  plt.xlabel('Predicted Labels', fontsize = 14)
  plt.ylabel('True Labels', fontsize = 14)
  plt.title(f'Confusion Matrix{name}', fontsize = 16)
  plt.show()

"""## **Data Oversampling**:
#### Applying SMOTE
when data is imbalanced, we apply SMOTE for oversampling and then balance data.
"""

# smote is used for oversampling not undersampling
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=42)
X_re, y_re = sm.fit_resample(X, Y) # resample (re) of X
X_train, X_test, Y_train, Y_test = train_test_split(X_re, y_re, test_size = 0.25)
X.head()

sns.countplot(x ='y', data = bank)
plt.title('Before applying SMOTE')
plt.show()

sns.countplot(x ='y', data = y_re)
plt.title('After applying SMOTE')
plt.show()

"""## **MODLING:**"""

models = {
    "                     Logistic Regression": LogisticRegression(),
    "                    Gaussian Naive Bayes": GaussianNB(),
    "                     K-Nearest Neighbors": KNeighborsClassifier(),
    "                  Support Vector Machine": SVC(),
    "                            RandomForest": RandomForestClassifier(),
    "                  DecisionTreeClassifier": DecisionTreeClassifier()
}


for name, model in models.items():
    model.fit(X_train, Y_train)
    print(name + " trained.")

for name, model in models.items():
    print(name + ": {:.2f}%".format(model.score(X_test, Y_test) * 100))

for name, model in models.items():
  y_pred = model.predict(X_test)
  # PRINT THE CONFUSION MATRIX
  print("Confusion Matrix")
  cm = confusion_matrix(Y_test, y_pred)
  print(cm)
  plt.figure(figsize = (6, 4))
  sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues', cbar = False, annot_kws = {'size' : 14})
  plt.xlabel('Predicted Labels', fontsize = 14)
  plt.ylabel('True Labels', fontsize = 14)
  plt.title('Confusion Matrix', fontsize = 16)
  plt.show()

X_test.head()

for name, model in models.items():
  y_predicted= model.predict(X_test)
  print(name , "Prediction : ",y_predicted)

"""#### Save in File"""

# dataset of predicted values for target variable y
prediction= pd.DataFrame(y_predicted, columns=["y_predicted"])

prediction_dataset= pd.concat([X_test, prediction], axis=1)
prediction_dataset
prediction_dataset.to_csv('output.csv', index=False)

"""## **Classification Report:**"""

for name, model in models.items():
  y_pred = model.predict(X_test)
  # print classification report
  print("Classification Report")
  cm = classification_report(Y_test, y_pred)
  print(cm)